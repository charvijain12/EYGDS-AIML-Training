import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import ConversationChain

load_dotenv()

#------------------------------------------------------------------
# Load API key and base URL from env variables
api_key = os.getenv("OPENROUTER_API_KEY")
base_url = os.getenv("OPENROUTER_BASE_URL", "https://openrouter.ai/api/v1")

# Check if API key is missing
if not api_key:
    raise ValueError("OPENROUTER_API_KEY not found in .env file")

# Initializing the language model
llm = ChatOpenAI(
    model="mistralai/mistral-7b-instruct",
    temperature=0.4,
    max_tokens=256,
    api_key=api_key,
    base_url=base_url,
)

# Initializing conversation memory
memory = ConversationBufferMemory(return_messages=True)
conversation = ConversationChain(
    llm=llm,
    memory=memory
)

# Start chat session
print("\n=== Start chatting with the Agent ===")
print("Type 'exit' to quit.\n")

while True:
    user_input = input("You: ").strip()
    if user_input.lower() == "exit":
        print("\nConversation ended.")
        break
    try:
        res = conversation(user_input)
        print("Agent:", res['response'])
    except Exception as e:
        print("Error:", e)
